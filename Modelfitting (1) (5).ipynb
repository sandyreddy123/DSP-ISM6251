{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de1261f6-11ae-4d50-b73e-2cbcbc416b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f681ff3-92be-45fe-92f5-d059fcb12760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Csv Data files of test and train\n",
    "\n",
    "X_test= pd.read_csv(\"C:/Users/ssand/OneDrive/Desktop/pre/X_test.csv\")\n",
    "X_train= pd.read_csv(\"C:/Users/ssand/OneDrive/Desktop/pre/X_train.csv\")\n",
    "y_test= pd.read_csv(\"C:/Users/ssand/OneDrive/Desktop/pre/y_test.csv\")\n",
    "y_train= pd.read_csv(\"C:/Users/ssand/OneDrive/Desktop/pre/y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c904ba-842f-40e7-aae4-5ff53d587980",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4607f58b-90c5-4519-97a5-bed7789df8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The best precision score is 0.7\n",
      "... with parameters: {'C': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan 0.6 0.6 0.6 0.6 0.7]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [       nan 0.97142857 0.97142857 1.         1.         1.        ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = [{'penalty':['l1','l2']}, \n",
    "              {'C':[1, 10, 100, 1000]}]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator =lr, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac0575f-6b21-4ccf-9b1e-04e762f10e88",
   "metadata": {},
   "source": [
    "We done the logistic regression with grid search the precision score is 0.7 and the precision for this seen better and going further we will the precision score for other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "debf69c4-6a3b-4ef7-a42b-21f851bf1460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best precision score is 0.7\n",
      "... with parameters: {'C': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 4 is smaller than n_iter=300. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = [\n",
    "              {'C':[1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "gs = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = gs, param_distributions=param_grid, cv=kfolds, n_iter=300,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecall= rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabec53d-cb54-4bc1-bc0a-cdf3224e3e8c",
   "metadata": {},
   "source": [
    "The logistic regression with random search the precision value is 0.7 which is better and we got the same for both grid and random search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a389c-b690-4961-b19a-422fd343f595",
   "metadata": {},
   "source": [
    "svm linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d25cda1-b221-4dea-b374-0419d252d749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best precision score is 0.6\n",
      "... with parameters: {'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = [  {'C':[1, 10, 100, 1000]}]\n",
    "\n",
    "sm =SVC()\n",
    "grid_search = GridSearchCV(estimator =sm, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a4db9-1134-4175-b0c1-180f3667ce95",
   "metadata": {},
   "source": [
    "The grid search using SVM linear model the prescision score is 0.6 which is less than the logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73c3c170-30af-490d-b92a-22ffde57b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best precision score is 0.6\n",
      "... with parameters: {'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 4 is smaller than n_iter=300. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = [\n",
    "              {'C':[1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "gs = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = gs, param_distributions=param_grid, cv=kfolds, n_iter=300,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecall= rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940ac981-340f-4d31-9fff-357549eb70d5",
   "metadata": {},
   "source": [
    "The randomsearch using SVM linear model the precision is 0.6 abd its same for grid and random search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa55f1-26c4-4791-a657-67c813f242e0",
   "metadata": {},
   "source": [
    "SVM with rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73ebcb80-842e-472f-8d7b-f4aa01c8f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best precision score is 0.6\n",
      "... with parameters: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = [\n",
    "              {'C':[1, 10, 100, 1000]}]\n",
    "\n",
    "Sk = SVC()\n",
    "grid_search = GridSearchCV(estimator =Sk, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca402d-d72d-409c-a201-baec12d73048",
   "metadata": {},
   "source": [
    "We done SVM with rbf kernel the precision score is 0.6 which is same as Svm with linear model for both grid and random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8778595-a93e-4d18-9f2c-1fdf49dd155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best precision score is 0.6\n",
      "... with parameters: {'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 4 is smaller than n_iter=300. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = [\n",
    "              {'C':[1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "gs = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = gs, param_distributions=param_grid, cv=kfolds, n_iter=300,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecall= rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221901a0-36c1-45c4-b357-dc846df924d2",
   "metadata": {},
   "source": [
    "The precision value for SVM  rbf kernel with random search is 0.6 which is same as svm rbf kernel with grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1600a565-3d0f-4d93-bd5a-07866004163e",
   "metadata": {},
   "source": [
    "Svm with poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9bca836-e41c-41c2-9db6-a46f36a50c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best precision score is 0.6\n",
      "... with parameters: {'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = [\n",
    "              {'C':[1, 10, 100, 1000]}]\n",
    "\n",
    "PK = SVC()\n",
    "grid_search = GridSearchCV(estimator =PK, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56055422-f941-4a90-ad60-6ed1f3c36189",
   "metadata": {},
   "source": [
    "The precision score for SVM with poly kernel with grid search is 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7c9a574-493c-49f5-b72c-6c9b58dc4846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best precision score is 0.6\n",
      "... with parameters: {'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 4 is smaller than n_iter=300. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = [\n",
    "              {'C':[1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "PR = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = PR, param_distributions=param_grid, cv=kfolds, n_iter=300,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecall= rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304dd466-912d-4ad7-8629-80594936d0be",
   "metadata": {},
   "source": [
    "The precision score for randomsearch with svm with poly kernel is 0.6 and as we can see we got the same precision value for all the SVM models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf048d-a5ea-428c-92a7-693634a2da3a",
   "metadata": {},
   "source": [
    "fitting DTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76ed7c40-c517-4aeb-968e-0c470ed15c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree1 = DecisionTreeClassifier().fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc19452c-3a0b-4ba6-a1bf-e17a40a56c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57462233-0c1e-4729-a633-c1497b4cf337",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,100),  \n",
    "    'min_samples_leaf': np.arange(1,100),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14c2d9f1-d735-4e01-9565-db066f3ba4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=300,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aab226ea-3355-4dd0-81d0-3ce674153c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "The best precision score is 0.5\n",
      "... with parameters: {'min_samples_split': 6, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.004600000000000001, 'max_leaf_nodes': 78, 'max_depth': 14, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "25 fits failed out of a total of 1500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\tree\\_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.23333333        nan 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333        nan 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333        nan\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333        nan 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.5\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333        nan 0.23333333 0.23333333 0.23333333\n",
      " 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333 0.23333333]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.31818182        nan 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182        nan 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182        nan\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182        nan 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.82857143\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182        nan 0.31818182 0.31818182 0.31818182\n",
      " 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182 0.31818182]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e8fbe6-878b-4873-9394-e0218c8f733d",
   "metadata": {},
   "source": [
    "The precision score for Decision tree with random search is 0.53 which less compared to all other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e0b2c3d-0a10-493f-8e4c-6793a9e08fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2400 candidates, totalling 12000 fits\n",
      "The best precision score is 0.2333333333333333\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 15, 'max_leaf_nodes': 60, 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 10, 'min_samples_split': 40}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(40,44),  \n",
    "    'min_samples_leaf': np.arange(10,16),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.001,0.0005),\n",
    "    'max_leaf_nodes': np.arange(60,70), \n",
    "    'max_depth': np.arange(15,20), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5484db-f75e-483a-a504-a152fd296ec5",
   "metadata": {},
   "source": [
    "The precision score for Decision tree with grid search is 0.23 which is way less than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac930b15-c7a3-4186-af3e-8ca82510b4b1",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "We can clearly see that the precision score for logistic regression is 0.7 and  which is higher compared to all other models for the given dataset.The best model fitting for this dataset is logistic model. So, the regeneration of lympography inside the body has a positive rate of 70 percent chances based on all other parameters.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f293d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f76cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.62      0.76        42\n",
      "           2       0.16      1.00      0.27         3\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.58      0.81      0.52        45\n",
      "weighted avg       0.94      0.64      0.73        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ann.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d7f4ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.01, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (40, 20), 'alpha': 0, 'activation': 'logistic'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75        42\n",
      "           2       0.15      1.00      0.26         3\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.57      0.80      0.50        45\n",
      "weighted avg       0.94      0.62      0.71        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#with random search cv\n",
    "\n",
    "\n",
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cef5f32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'tanh', 'alpha': 0.5, 'hidden_layer_sizes': (30,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 5000, 'solver': 'adam'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.67      0.80        42\n",
      "           2       0.18      1.00      0.30         3\n",
      "\n",
      "    accuracy                           0.69        45\n",
      "   macro avg       0.59      0.83      0.55        45\n",
      "weighted avg       0.95      0.69      0.77        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48f1b1d2",
   "metadata": {},
   "source": [
    "After, adding neural network  to this dataset we can see the precision weight avg value with random search is 0.94 and precision weight avg value with grid search is 0.95. We got precison value for logistic regression is 0.7 clearly we can say the neural network  performmed better with this dataset and got an high precision value with both grid and random search for this dataset. If we compare in bewteen this two the grid search performmed better than random search overall in neural network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa345f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
